{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "The following code scrapes data from the premier league website. There are a total of 42 stats (some of which may need to be discarded) that it collects for each team from season 2006-2007 until 2017-2018, making it an approximate total of 504 web requests performed. These stats will serve as features of a dataset that'll be fed into an ANN and RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "Building wheels for collected packages: progressbar\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=26c4f550b0a8b87b352d93e57289cb9cb25ae04fdc9c742a1a2476302f02defd\n",
      "  Stored in directory: /Users/ali/Library/Caches/pip/wheels/d7/d9/89/a3f31c76ff6d51dc3b1575628f59afe59e4ceae3f2748cd7ad\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 soupsieve-2.5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/ali/Library/Python/3.9/lib/python/site-packages (2.2.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/ali/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ali/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ali/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ali/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.0\n",
      "    Uninstalling pandas-2.2.0:\n",
      "      Successfully uninstalled pandas-2.2.0\n",
      "Successfully installed pandas-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import progressbar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "webpage = requests.get('https://www.premierleague.com/stats/top/clubs/wins?se=578')\n",
    "soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "\n",
    "if not os.path.exists('files'):\n",
    "    os.makedirs('files/stats')\n",
    "    os.makedirs('files/results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**select** is used instead of find_all since it allows the use of javascript selectors <br>\n",
    "\n",
    "------\n",
    "\n",
    "**General** <br>\n",
    "*index 0-5* <br>\n",
    "wins, losses, goals, yellow cards, red cards, substitutions on\n",
    "\n",
    "**Attack** <br>\n",
    "*index 6-15* <br>\n",
    "shots, shots on target, hit woodwork, goals from header, goals from penalty, goals from free kick, goals from inside box, goals from outside box, goals from counter attack, offsides\n",
    "\n",
    "**Defence** <br>\n",
    "*index 16-29* <br>\n",
    "clean sheets, goals conceded, saves, blocks, interceptions, tackles, last man tackles, clearances, headed clearances, caught opponent offside, own goals, penalties conceded, goals conceded from penalty, fouls\n",
    "\n",
    "**Team Play** <br>\n",
    "*index 30-35* <br>\n",
    "passes, through balls, long passes, backwards passes, crosses, corners taken\n",
    "\n",
    "**Others** <br>\n",
    "*index 36-42 <br>\n",
    "non-duplicates attributes from top i.e. don't appear in more*  <br>\n",
    "touches, big chances missed, clearances off line, dispossessed, penalties saved, high claims, punches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attributes(links):\n",
    "    return [link[link.rfind('/')+1:] for link in links]\n",
    "\n",
    "def uniques(links):\n",
    "    l = []\n",
    "    for link in links:\n",
    "        if link not in l:\n",
    "            l.append(link)\n",
    "    return l\n",
    "\n",
    "top = [link['href'] for link in soup.select('a.topStatsLink')]\n",
    "more = [link['href'] for link in soup.select('nav.moreStatsMenu a')]\n",
    "links = uniques(attributes(more) + attributes(top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "\n",
    "Data is being collected from the 2006/2007 season since detailed and constant stats were collected from then onwards.\n",
    "\n",
    "Dates (i.e. seasons and their corresponding ids) cannot be scraped since it doesn't appear in the html so I'll manually extract it from the html that Chrome Dev Tools displays. Note that this html often varies to the plain output html from cURL or when downloading the page since the browser is capable of executing some js and changing the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = {'2006-2007':15, '2007-2008':16, '2008-2009':17, '2009-2010':18, \n",
    "         '2010-2011':19, '2011-2012':20, '2012-2013':21, '2013-2014':22, \n",
    "         '2014-2015':27, '2015-2016':42, '2016-2017':54, '2017-2018':79,\n",
    "         '2018-2019':210, '2019-2020':274, '2020-2021':363, '2021-2022':418,\n",
    "         '2022-2023':489, '2023-2024':578}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "\n",
    "The data couldn't be scraped from the webpage since the site uses ajax to update the table that includes the stats i.e. when you visit the webpage for a specific attribute (one of the links), the html contains the data for 'all seasons' and when you choose a particular season then the table is updated using ajax meaning that the source doesn't reflect the new values and still (and only will) show the data for 'all seasons'.\n",
    "\n",
    "To hack around this, visit the Network tab of Chrome Dev Tools and filter response resources by XHR (i.e. XML and JSON documents from XMLHttpRequests) - which is responses from AJAX requests. We can see that the last document contains the data from the ajax request and is what we need, however we can't simply send a get request for the link to that JSON document because it's an API that needs to authorise the request source. This will result in a 403 forbidden response. \n",
    "\n",
    "To get around that last hurdle, we need to include the headers (particularly general and request) sent by the premier league website to the API to block our identity and clone the premier league's. We get the required headers from the same place in the Chrome Dev Tools, clicking on the JSON document/response needed, and then clicking on the Headers tab of the panel to the right.\n",
    "\n",
    "https://www.agenty.com/docs/how-to/18/how-to-crawl-an-infinite-scrolling-ajax-website <br>\n",
    "https://www.codementor.io/codementorteam/how-to-scrape-an-ajax-website-using-python-qw8fuitvi <br>\n",
    "https://www.quora.com/What-are-the-best-ways-to-scrape-the-AJAX-driven-websites <br>\n",
    "https://stackoverflow.com/questions/44080707/web-scraping-a-strange-html-setup-with-python-beautifulsoup-urllib\n",
    "\n",
    "-----\n",
    "\n",
    "One thing that was noticed is that if there's a NaN value for all teams for a certain attribute then that stat wasn't collected, however, if it's just for some/few teams then the value for that team is meant to be 0 e.g. red cards for Burnley in 2017-2018 was 0 as per their stats page (https://www.premierleague.com/clubs/43/Burnley/stats?se=79) but the page where the data is sourced from (https://www.premierleague.com/stats/top/clubs/total_red_card?se=79) doesn't display them in the table since their value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2006-2007\t[                                                              ]   0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2006-2007\t[--------------------------------------------------------------] 100%\n",
      "2007-2008\t[--------------------------------------------------------------] 100%\n",
      "2008-2009\t[--------------------------------------------------------------] 100%\n",
      "2009-2010\t[--------------------------------------------------------------] 100%\n",
      "2010-2011\t[--------------------------------------------------------------] 100%\n",
      "2011-2012\t[--------------------------------------------------------------] 100%\n",
      "2012-2013\t[--------------------------------------------------------------] 100%\n",
      "2013-2014\t[--------------------------------------------------------------] 100%\n",
      "2014-2015\t[--------------------------------------------------------------] 100%\n",
      "2015-2016\t[--------------------------------------------------------------] 100%\n",
      "2016-2017\t[--------------------------------------------------------------] 100%\n",
      "2017-2018\t[--------------------------------------------------------------] 100%\n",
      "2018-2019\t[--------------------------------------------------------------] 100%\n",
      "2019-2020\t[--------------------------------------------------------------] 100%\n",
      "2020-2021\t[--------------------------------------------------------------] 100%\n",
      "2021-2022\t[--------------------------------------------------------------] 100%\n",
      "2022-2023\t[--------------------------------------------------------------] 100%\n",
      "2023-2024\t[--------------------------------------------------------------] 100%\n"
     ]
    }
   ],
   "source": [
    "for date in dates.keys():\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    bar = progressbar.ProgressBar(maxval=len(links), widgets=[date + '\\t', progressbar.Bar('-', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    for i, attribute in zip(range(len(links)), links):\n",
    "\n",
    "        # setup\n",
    "        api = 'https://footballapi.pulselive.com/football/stats/ranked/teams/' + attribute\n",
    "        headers = {'Origin': 'https://www.premierleague.com'}\n",
    "        params = {'page': '0', 'pageSize': '20', 'compSeasons': dates[date], 'comps': '1', 'altIds': 'true'}\n",
    "\n",
    "        # request\n",
    "        response = requests.get(api, params=params, headers=headers)\n",
    "        data = json.loads(response.text)\n",
    "\n",
    "        # parse\n",
    "        teams = []; values = [];\n",
    "        for team in data['stats']['content']:\n",
    "            teams.append(team['owner']['name'])\n",
    "            values.append(team['value'])\n",
    "        series = pd.Series(values, teams, float, attribute)\n",
    "        if df.index.empty:\n",
    "            df = pd.DataFrame(series)\n",
    "        else:\n",
    "            df = df.join(series)\n",
    "\n",
    "        # progress\n",
    "        bar.update(i+1)\n",
    "\n",
    "    bar.finish()\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.to_csv('files/stats/' + date + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-2007\t19\n",
      "2007-2008\t20\n",
      "2008-2009\t20\n",
      "2009-2010\t20\n",
      "2010-2011\t21\n",
      "2011-2012\t21\n",
      "2012-2013\t21\n",
      "2013-2014\t21\n",
      "2014-2015\t21\n",
      "2015-2016\t21\n",
      "2016-2017\t21\n",
      "2017-2018\t21\n",
      "2018-2019\t21\n",
      "2019-2020\t21\n",
      "2020-2021\t21\n",
      "2021-2022\t21\n",
      "2022-2023\t21\n",
      "2023-2024\t21\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for date in dates.keys():\n",
    "    dataset = pd.read_csv('files/stats/' + date + '.csv', index_col=0)\n",
    "    datasets.append(dataset)\n",
    "    print(date + '\\t' + str(len(dataset.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the number of statistics collected for each team for each of the listed seasons. We can see that there only seems to be consistency from season 2010-2011 onwards because there are the same number of stats collected. To validate that, we'll see if the stats are the same ones collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Set\n"
     ]
    }
   ],
   "source": [
    "mismatches = []\n",
    "\n",
    "for i in range(4,12):\n",
    "    for j in range(i+1,12):\n",
    "        if datasets[i].columns.tolist() != datasets[j].columns.tolist():\n",
    "            mismatches.append((i,j))\n",
    "            \n",
    "if len(mismatches) == 0:\n",
    "    print('Valid Set')\n",
    "else:\n",
    "    print('Invalid Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_ids(date):\n",
    "    # setup\n",
    "    api = 'https://footballapi.pulselive.com/football/compseasons/' + str(dates[date]) + '/teams'\n",
    "    headers = {'Origin': 'https://www.premierleague.com'}\n",
    "    \n",
    "    # request\n",
    "    response = requests.get(api, headers=headers)\n",
    "    teams = json.loads(response.text)\n",
    "    \n",
    "    # parse\n",
    "    team_ids = []\n",
    "    for team in teams:\n",
    "        team_ids.append(int(team['id']))\n",
    "    team_ids = ','.join(map(str, team_ids))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_results(date, team_ids):\n",
    "    # setup\n",
    "    api = 'https://footballapi.pulselive.com/football/fixtures'\n",
    "    headers = {'Origin': 'https://www.premierleague.com'}\n",
    "    params = {'comps':'1', 'compSeasons':dates[date], 'teams':team_ids, 'page':'0', 'pageSize':'380', 'sort':'asc', 'statuses':'C', 'altIds':'true'}\n",
    "\n",
    "    # request\n",
    "    response = requests.get(api, params=params, headers=headers)\n",
    "    results = json.loads(response.text)\n",
    "    \n",
    "    # parse\n",
    "    df = pd.DataFrame(columns=['home_team', 'away_team', 'home_goals', 'away_goals', 'result'])\n",
    "    for result in results['content']:\n",
    "        row = []\n",
    "        row.append(result['teams'][0]['team']['name'])\n",
    "        row.append(result['teams'][1]['team']['name'])\n",
    "        row.append(result['teams'][0]['score'])\n",
    "        row.append(result['teams'][1]['score'])\n",
    "        row.append(result['outcome'])\n",
    "        row = pd.Series(row, index=df.columns)\n",
    "        df = df.append(row, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t[                                                                       ]   0%\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7s/byhf_72x0gbg7s7mbc_wxtj40000gn/T/ipykernel_45583/1884836989.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'['\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPercentage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mteam_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_team_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7s/byhf_72x0gbg7s7mbc_wxtj40000gn/T/ipykernel_45583/225621546.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(date, team_ids)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'teams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'teams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6290\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mwarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6292\u001b[0m                \u001b[0mThe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrently\u001b[0m \u001b[0mconsidered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6293\u001b[0;31m                \u001b[0mstable\u001b[0m \u001b[0macross\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mreleases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6294\u001b[0m         \"\"\"\n\u001b[1;32m   6295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar(maxval=len(dates), widgets=['', '\\t', progressbar.Bar('-', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "for i, date in zip(range(len(dates)), dates.keys()):\n",
    "    bar.widgets[0] = date\n",
    "    team_ids = get_team_ids(date)\n",
    "    results = get_results(date, team_ids)\n",
    "    bar.update(i+1)\n",
    "    results.to_csv('files/results/' + date + '.csv')\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "\n",
    "Concatenating the discrete sets for each season into one big set that contains all seasons - one for stats and another for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['2006-2007.csv', '2007-2008.csv', '2008-2009.csv', '2009-2010.csv', '2010-2011.csv', '2011-2012.csv', '2012-2013.csv', '2013-2014.csv', '2014-2015.csv', '2015-2016.csv', '2016-2017.csv', '2017-2018.csv']\n",
    "\n",
    "stats_df = pd.DataFrame()\n",
    "results_df = pd.DataFrame()\n",
    "for name in files:\n",
    "    \n",
    "    # Stats\n",
    "    f = 'files/stats/' + name\n",
    "    stats_series = pd.Series([name[:-4]]*20, name='season')\n",
    "    stats_season = pd.concat([pd.read_csv(f, index_col=False), stats_series], axis=1)\n",
    "    columns = stats_season.columns.tolist(); columns[0] = 'team'; stats_season.columns = columns\n",
    "    if stats_df.empty:\n",
    "        stats_df = stats_season\n",
    "    else:\n",
    "        stats_df = pd.concat([stats_df, stats_season])\n",
    "        \n",
    "    # Results\n",
    "    f = 'files/results/' + name\n",
    "    results_series = pd.Series([name[:-4]]*380, name='season')\n",
    "    results_season = pd.concat([pd.read_csv(f), results_series], axis=1)\n",
    "    if results_df.empty:\n",
    "        results_df = results_season\n",
    "    else:\n",
    "        results_df = pd.concat([results_df, results_season])\n",
    "    \n",
    "stats_df = stats_df[stats_season.columns.tolist()]\n",
    "stats_df.to_csv('files/stats/stats.csv', index=False)\n",
    "\n",
    "results_df.drop(results_df.columns[0], axis=1, inplace=True)\n",
    "results_df.to_csv('files/results/results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
